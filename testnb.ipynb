{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T13:01:19.413331Z",
     "start_time": "2024-10-29T13:01:15.444972Z"
    }
   },
   "source": "%pip install llamaapi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llamaapi in c:\\users\\anwender\\anaconda3\\lib\\site-packages (0.1.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.5 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from llamaapi) (3.8.5)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from llamaapi) (1.5.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from llamaapi) (2.31.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.27.1->llamaapi) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:01:24.318408Z",
     "start_time": "2024-10-29T13:01:22.540409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from llamaapi import LlamaAPI\n",
    "\n",
    "# Initialize the SDK\n",
    "llama = LlamaAPI(\"api_key\")\n",
    "\n",
    "# Build the API request\n",
    "api_request_json = {\n",
    "    \"model\": \"llama3.1-70b\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in Vienna?\"},\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"days\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"for how many days ahead you wants the forecast\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"days\"],\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"function_call\": \"get_current_weather\",\n",
    "}\n",
    "\n",
    "# Execute the Request\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))\n"
   ],
   "id": "a3a77ea57786ac66",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "POST 401 Insufficient balance.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 39\u001B[0m\n\u001B[0;32m      8\u001B[0m api_request_json \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama3.1-70b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_current_weather\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     36\u001B[0m }\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Execute the Request\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m response \u001B[38;5;241m=\u001B[39m llama\u001B[38;5;241m.\u001B[39mrun(api_request_json)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(json\u001B[38;5;241m.\u001B[39mdumps(response\u001B[38;5;241m.\u001B[39mjson(), indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llamaapi\\llamaapi.py:67\u001B[0m, in \u001B[0;36mLlamaAPI.run\u001B[1;34m(self, api_request_json)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_stream(api_request_json)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_sync(api_request_json)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llamaapi\\llamaapi.py:53\u001B[0m, in \u001B[0;36mLlamaAPI.run_sync\u001B[1;34m(self, api_request_json)\u001B[0m\n\u001B[0;32m     51\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhostname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdomain_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, headers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders, json\u001B[38;5;241m=\u001B[39mapi_request_json)\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:        \n\u001B[1;32m---> 53\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mjson()[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdetail\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[1;31mException\u001B[0m: POST 401 Insufficient balance."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:51:29.921720Z",
     "start_time": "2024-10-29T13:51:25.879670Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install openai",
   "id": "ebf5d5012c7a40ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\anwender\\anaconda3\\lib\\site-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (1.10.18)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:52:03.234597Z",
     "start_time": "2024-10-29T13:52:02.925346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#https://platform.openai.com/docs/quickstart?desktop-os=windows&language-preference=python\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "\n"
   ],
   "id": "94ee56c3b120250c",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model_json_schema' from 'openai._compat' (C:\\Users\\Anwender\\anaconda3\\Lib\\site-packages\\openai\\_compat.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mopenai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAI\n\u001B[0;32m      2\u001B[0m client \u001B[38;5;241m=\u001B[39m OpenAI()\n\u001B[0;32m      4\u001B[0m completion \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m      5\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-4o-mini\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m     messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m     ]\n\u001B[0;32m     13\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\__init__.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m file_from_path\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_client\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Client, OpenAI, Stream, Timeout, Transport, AsyncClient, AsyncOpenAI, AsyncStream, RequestOptions\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __title__, __version__\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_client.py:11\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping_extensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Self, override\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mhttpx\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m resources, _exceptions\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_qs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Querystring\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     14\u001B[0m     NOT_GIVEN,\n\u001B[0;32m     15\u001B[0m     Omit,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     RequestOptions,\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbeta\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Beta,\n\u001B[0;32m      5\u001B[0m     AsyncBeta,\n\u001B[0;32m      6\u001B[0m     BetaWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncBetaWithRawResponse,\n\u001B[0;32m      8\u001B[0m     BetaWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncBetaWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Chat,\n\u001B[0;32m     13\u001B[0m     AsyncChat,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncChatWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     Audio,\n\u001B[0;32m     21\u001B[0m     AsyncAudio,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     AsyncAudioWithStreamingResponse,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbeta\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Beta,\n\u001B[0;32m      5\u001B[0m     AsyncBeta,\n\u001B[0;32m      6\u001B[0m     BetaWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncBetaWithRawResponse,\n\u001B[0;32m      8\u001B[0m     BetaWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncBetaWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Threads,\n\u001B[0;32m     13\u001B[0m     AsyncThreads,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncThreadsWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01massistants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     Assistants,\n\u001B[0;32m     21\u001B[0m     AsyncAssistants,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     AsyncAssistantsWithStreamingResponse,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\beta.py:5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m annotations\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      6\u001B[0m     Threads,\n\u001B[0;32m      7\u001B[0m     AsyncThreads,\n\u001B[0;32m      8\u001B[0m     ThreadsWithRawResponse,\n\u001B[0;32m      9\u001B[0m     AsyncThreadsWithRawResponse,\n\u001B[0;32m     10\u001B[0m     ThreadsWithStreamingResponse,\n\u001B[0;32m     11\u001B[0m     AsyncThreadsWithStreamingResponse,\n\u001B[0;32m     12\u001B[0m )\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cached_property\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01massistants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     15\u001B[0m     Assistants,\n\u001B[0;32m     16\u001B[0m     AsyncAssistants,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     AsyncAssistantsWithStreamingResponse,\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\threads\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Runs,\n\u001B[0;32m      5\u001B[0m     AsyncRuns,\n\u001B[0;32m      6\u001B[0m     RunsWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncRunsWithRawResponse,\n\u001B[0;32m      8\u001B[0m     RunsWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncRunsWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Threads,\n\u001B[0;32m     13\u001B[0m     AsyncThreads,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncThreadsWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     Messages,\n\u001B[0;32m     21\u001B[0m     AsyncMessages,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     AsyncMessagesWithStreamingResponse,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Runs,\n\u001B[0;32m      5\u001B[0m     AsyncRuns,\n\u001B[0;32m      6\u001B[0m     RunsWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncRunsWithRawResponse,\n\u001B[0;32m      8\u001B[0m     RunsWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncRunsWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msteps\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Steps,\n\u001B[0;32m     13\u001B[0m     AsyncSteps,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncStepsWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     20\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSteps\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsyncSteps\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsyncRunsWithStreamingResponse\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     33\u001B[0m ]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\runs.py:34\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_streaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Stream, AsyncStream\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpagination\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SyncCursorPage, AsyncCursorPage\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_base_client\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m---> 34\u001B[0m     AsyncPaginator,\n\u001B[0;32m     35\u001B[0m     make_request_options,\n\u001B[0;32m     36\u001B[0m )\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstreaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     38\u001B[0m     AssistantEventHandler,\n\u001B[0;32m     39\u001B[0m     AssistantEventHandlerT,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     43\u001B[0m     AsyncAssistantStreamManager,\n\u001B[0;32m     44\u001B[0m )\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbeta\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     46\u001B[0m     run_list_params,\n\u001B[0;32m     47\u001B[0m     run_create_params,\n\u001B[0;32m     48\u001B[0m     run_update_params,\n\u001B[0;32m     49\u001B[0m     run_submit_tool_outputs_params,\n\u001B[0;32m     50\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pydantic_function_tool \u001B[38;5;28;01mas\u001B[39;00m pydantic_function_tool\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_parsing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ResponseFormatT \u001B[38;5;28;01mas\u001B[39;00m ResponseFormatT\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\_tools.py:7\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, cast\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_strict_json_schema\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ChatCompletionToolParam\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mshared_params\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FunctionDefinition\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\_pydantic.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NOT_GIVEN\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_dict \u001B[38;5;28;01mas\u001B[39;00m _is_dict, is_list\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PYDANTIC_V2, model_json_schema\n\u001B[0;32m     13\u001B[0m _T \u001B[38;5;241m=\u001B[39m TypeVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_T\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_strict_json_schema\u001B[39m(model: \u001B[38;5;28mtype\u001B[39m[pydantic\u001B[38;5;241m.\u001B[39mBaseModel] \u001B[38;5;241m|\u001B[39m pydantic\u001B[38;5;241m.\u001B[39mTypeAdapter[Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]:\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'model_json_schema' from 'openai._compat' (C:\\Users\\Anwender\\anaconda3\\Lib\\site-packages\\openai\\_compat.py)"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T16:12:59.016414Z",
     "start_time": "2024-10-29T16:12:58.324577Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install ollama",
   "id": "7ca5a2b8c7301944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\r\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from ollama) (0.27.0)\r\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\r\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.11.0)\r\n",
      "Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\r\n",
      "Installing collected packages: ollama\r\n",
      "Successfully installed ollama-0.3.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T16:26:51.788326Z",
     "start_time": "2024-10-29T16:26:48.009294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me an interesting fact about elephants\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ],
   "id": "64de44d737780c13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a fascinating fact about elephants:\n",
      "\n",
      "Elephants have a highly developed sense of empathy and can recognize and respond to the emotions of others. In fact, they are considered one of the most empathetic animals on Earth.\n",
      "\n",
      "Studies have shown that when an elephant experiences stress or distress, its family members will often gather around it and provide support and comfort. They may even touch each other with their trunks in a gentle, reassuring manner.\n",
      "\n",
      "This empathy is thought to be linked to the large size and complexity of an elephant's brain, which contains a high concentration of neurons that are dedicated to emotional processing. It's believed that this advanced emotional intelligence allows elephants to pick up on subtle social cues and respond with compassion and care.\n",
      "\n",
      "Isn't that amazing?\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:53:51.953485Z",
     "start_time": "2024-11-15T08:53:46.111825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Function to read the content of a PDF document\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Replace this with the path to your PDF document\n",
    "file_path = \"resources/business_rules_document.pdf\"\n",
    "\n",
    "# Read the content of the PDF document\n",
    "document_content = read_pdf(file_path)\n",
    "\n",
    "# Create the Ollama API request\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"I have the following document: {document_content}\\n\\n extract all the business rules from this document. Present them clearly in a bullet-point format.\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Extract and print the response\n",
    "print(response[\"message\"][\"content\"])\n"
   ],
   "id": "670c08e96921729c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted business rules in a clear bullet-point format:\n",
      "\n",
      "• **Customer Onboarding**: Customers must provide valid identification before opening an account.\n",
      "\n",
      "• **Transaction Reporting**: All transactions above $10,000 must be reported to the compliance department.\n",
      "\n",
      "• **Loan Application Processing**: Loan applications can only be processed if the applicant has a credit score of 650 or above.\n",
      "\n",
      "• **Expense Report Approval**: Employees are not allowed to approve their own expense reports.\n",
      "\n",
      "• **Refund Policy**: Refunds are only issued if the request is made within 30 days of the purchase date.\n",
      "\n",
      "• **Discount Approval**: A manager must approve any discount greater than 20%.\n",
      "\n",
      "• **Terms and Conditions**: Customers must agree to the terms and conditions before using the service.\n",
      "\n",
      "• **Customer Data Protection**: All customer data must be encrypted when stored or transmitted.\n",
      "\n",
      "• **Vendor Verification**: Vendors must be vetted and approved by the procurement team before any contracts are signed.\n",
      "\n",
      "• **Inventory Management**: Inventory checks must be conducted at the end of each month.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:54:21.153265Z",
     "start_time": "2024-11-15T08:54:13.932085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "# Initialize the Ollama model\n",
    "#ollama.initialize_model(\"ollama-legal-extraction\")\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_rules_from_text(text):\n",
    "    # Step 1: Segment and preprocess the text\n",
    "    #segments = ollama.segment_text(text)\n",
    "    segmentsResponse = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"segment the text into logical segments use # to separate the segments: {text}\"\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    segments = segmentsResponse[\"message\"][\"content\"].split(\"#\")\n",
    "\n",
    "    extracted_rules = []\n",
    "\n",
    "    for segment in segments:\n",
    "        # Step 2: Extract rules using contextual understanding\n",
    "        prompt = f\"Identify legal rules in the following segment: {segment}\"\n",
    "        #response = ollama.generate(prompt)\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.2\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Step 3: Parse the response to get conditions and consequences\n",
    "        #parsed_rules = parse_response(response)\n",
    "        extracted_rules.append(response[\"message\"][\"content\"])\n",
    "\n",
    "    return extracted_rules\n",
    "\n",
    "def convert_to_prolog(logical_rules):\n",
    "    prolog_rules = []\n",
    "\n",
    "    for rule in logical_rules:\n",
    "        # Convert logical rule to Prolog format\n",
    "        prompt = f\"Convert this rule to Prolog: {rule}\"\n",
    "        responseProlog = ollama.chat(\n",
    "            model=\"llama3.2\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        prolog_rules.append(responseProlog[\"message\"][\"content\"])\n",
    "\n",
    "    return prolog_rules\n",
    "\n",
    "# Example usage\n",
    "# Replace this with the path to your PDF document\n",
    "file_path = \"resources/business_rules_document.pdf\"\n",
    "\n",
    "# Read the content of the PDF document\n",
    "legal_text = read_pdf(file_path)\n",
    "rules = extract_rules_from_text(legal_text)\n",
    "prolog_rules = convert_to_prolog(rules)\n",
    "prolog_rules_string = \"\\n\".join(prolog_rules)\n",
    "\n",
    "output = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Just return prolog rules in this text, don't simplify: {prolog_rules_string}\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Output the Prolog rules\n",
    "print(output[\"message\"][\"content\"])"
   ],
   "id": "3153f6e4491d43fc",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 75\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;66;03m# Read the content of the PDF document\u001B[39;00m\n\u001B[1;32m     74\u001B[0m legal_text \u001B[38;5;241m=\u001B[39m read_pdf(file_path)\n\u001B[0;32m---> 75\u001B[0m rules \u001B[38;5;241m=\u001B[39m \u001B[43mextract_rules_from_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlegal_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m prolog_rules \u001B[38;5;241m=\u001B[39m convert_to_prolog(rules)\n\u001B[1;32m     77\u001B[0m prolog_rules_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(prolog_rules)\n",
      "Cell \u001B[0;32mIn[3], line 34\u001B[0m, in \u001B[0;36mextract_rules_from_text\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     32\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIdentify legal rules in the following segment: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msegment\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m#response = ollama.generate(prompt)\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mollama\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mllama3.2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# Step 3: Parse the response to get conditions and consequences\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m#parsed_rules = parse_response(response)\u001B[39;00m\n\u001B[1;32m     46\u001B[0m extracted_rules\u001B[38;5;241m.\u001B[39mappend(response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/ollama/_client.py:236\u001B[0m, in \u001B[0;36mClient.chat\u001B[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001B[0m\n\u001B[1;32m    233\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m images \u001B[38;5;241m:=\u001B[39m message\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    234\u001B[0m     message[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [_encode_image(image) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images]\n\u001B[0;32m--> 236\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPOST\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/api/chat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m  \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mformat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moptions\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mkeep_alive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m  \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m  \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/ollama/_client.py:99\u001B[0m, in \u001B[0;36mClient._request_stream\u001B[0;34m(self, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_request_stream\u001B[39m(\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     95\u001B[0m   \u001B[38;5;241m*\u001B[39margs,\n\u001B[1;32m     96\u001B[0m   stream: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     97\u001B[0m   \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m     98\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Mapping[\u001B[38;5;28mstr\u001B[39m, Any], Iterator[Mapping[\u001B[38;5;28mstr\u001B[39m, Any]]]:\n\u001B[0;32m---> 99\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mif\u001B[39;00m stream \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/ollama/_client.py:70\u001B[0m, in \u001B[0;36mClient._request\u001B[0;34m(self, method, url, **kwargs)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, method: \u001B[38;5;28mstr\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m httpx\u001B[38;5;241m.\u001B[39mResponse:\n\u001B[0;32m---> 70\u001B[0m   response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     response\u001B[38;5;241m.\u001B[39mraise_for_status()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpx/_client.py:827\u001B[0m, in \u001B[0;36mClient.request\u001B[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[0m\n\u001B[1;32m    812\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[1;32m    814\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_request(\n\u001B[1;32m    815\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    816\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    825\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mextensions,\n\u001B[1;32m    826\u001B[0m )\n\u001B[0;32m--> 827\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpx/_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[0;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[1;32m    906\u001B[0m follow_redirects \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    907\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfollow_redirects\n\u001B[1;32m    908\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(follow_redirects, UseClientDefault)\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m follow_redirects\n\u001B[1;32m    910\u001B[0m )\n\u001B[1;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[0;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpx/_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[0;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[1;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[1;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpx/_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[0;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    977\u001B[0m     hook(request)\n\u001B[0;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpx/_client.py:1015\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m   1010\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1011\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1012\u001B[0m     )\n\u001B[1;32m   1014\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[0;32m-> 1015\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[1;32m   1019\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpx/_transports/default.py:233\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    220\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[1;32m    221\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    222\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    231\u001B[0m )\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m--> 233\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[1;32m    238\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[1;32m    239\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m    240\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[1;32m    241\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    242\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:268\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ShieldCancellation():\n\u001B[1;32m    267\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_closed(status)\n\u001B[0;32m--> 268\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:251\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    248\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 251\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001B[39;00m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;66;03m# indicates we need to retry the request on a new connection.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# up as HTTP/1.1.\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool_lock:\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;66;03m# Maintain our position in the request queue, but reset the\u001B[39;00m\n\u001B[1;32m    262\u001B[0m         \u001B[38;5;66;03m# status so that the request becomes queued again.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/connection.py:103\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m    101\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConnectionNotAvailable()\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/http11.py:133\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[0;32m--> 133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/http11.py:111\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[1;32m    105\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m    106\u001B[0m     (\n\u001B[1;32m    107\u001B[0m         http_version,\n\u001B[1;32m    108\u001B[0m         status,\n\u001B[1;32m    109\u001B[0m         reason_phrase,\n\u001B[1;32m    110\u001B[0m         headers,\n\u001B[0;32m--> 111\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    113\u001B[0m         http_version,\n\u001B[1;32m    114\u001B[0m         status,\n\u001B[1;32m    115\u001B[0m         reason_phrase,\n\u001B[1;32m    116\u001B[0m         headers,\n\u001B[1;32m    117\u001B[0m     )\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[1;32m    120\u001B[0m     status\u001B[38;5;241m=\u001B[39mstatus,\n\u001B[1;32m    121\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    127\u001B[0m     },\n\u001B[1;32m    128\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/http11.py:176\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    173\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 176\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[1;32m    178\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_sync/http11.py:212\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    209\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[0;32m--> 212\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/DataAndKnowledgeEngineering/lib/python3.8/site-packages/httpcore/_backends/sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[0;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cee60a82d2edc613"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T08:56:56.330206Z",
     "start_time": "2024-11-15T08:56:06.276899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from LLM import LLM\n",
    "from BusinessRuleExtractionLibrary import BusinessRuleExtractionLibrary\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "# Replace this with the path to your PDF document\n",
    "file_path = \"resources/business_rules_document.pdf\"\n",
    "\n",
    "# Read the content of the PDF document\n",
    "legal_text = read_pdf(file_path)\n",
    "\n",
    "# Create an instance of BusinessRuleExtractionLibrary\n",
    "ruleExtractor = BusinessRuleExtractionLibrary(LLM.OLLAMA)\n",
    "\n",
    "rules = ruleExtractor.extract_business_rules_from_document(legal_text)\n",
    "prolog_rules = convert_to_prolog(rules)\n",
    "prolog_rules_string = \"\\n\".join(prolog_rules)\n",
    "\n",
    "output = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Just return prolog rules in this text, don't simplify: {prolog_rules_string}\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Output the Prolog rules\n",
    "print(output[\"message\"][\"content\"])\n"
   ],
   "id": "b59de4d9edb1f9f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the Prolog rules:\n",
      "\n",
      "```prolog\n",
      "rule(acl, anti_money_laundering_rule).\n",
      "rule(bcl, consumer_protection_law).\n",
      "rule(dpl, data_privacy_and_security_law).\n",
      "rule(epl, employment_laws).\n",
      "rule(cpl, credit_reporting_laws).\n",
      "rule(tpl, tax_compliance_law).\n",
      "rule(tpcl, terms_and_conditions_law).\n",
      "\n",
      "description(rule(anti_money_laundering_rule), anti_money_laundering_rule).\n",
      "description(rule(consumer_protection_law), consumer_protection_law).\n",
      "description(rule(data_privacy_and_security_law), data_privacy_and_security_law).\n",
      "description(rule(employment_laws), employment_laws).\n",
      "description(rule(credit_reporting_laws), credit_reporting_laws).\n",
      "description(rule(tax_compliance_law), tax_compliance_law).\n",
      "description(rule(terms_and_conditions_law), terms_and_conditions_law).\n",
      "\n",
      "requirement(rule(anti_money_laundering_rule), $10,000).\n",
      "requirement(rule(consumer_protection_law), 30).\n",
      "requirement(rule(data_privacy_and_security_law), true).\n",
      "requirement(rule(employment_laws), false).\n",
      "requirement(rule(credit_reporting_laws), 650).\n",
      "requirement(rule(tax_compliance_law), 20).\n",
      "\n",
      "implication(rule(anti_money_laundering_rule), rule(consumer_protection_law)).\n",
      "implication(rule(data_privacy_and_security_law), rule(tpcl)).\n",
      "implication(rule(employment_laws), rule(epl)).\n",
      "implication(rule(credit_reporting_laws), rule(bcl)).\n",
      "implication(rule(tax_compliance_law), rule(tpl)).\n",
      "\n",
      "related(rule(acl, anti_money_laundering_rule),\n",
      "        rule(bcl, consumer_protection_law),\n",
      "        rule(dpl, data_privacy_and_security_law),\n",
      "        rule(epl, employment_laws),\n",
      "        rule(cpl, credit_reporting_laws),\n",
      "        rule(tpl, tax_compliance_law),\n",
      "        rule(tpcl, terms_and_conditions_law)).\n",
      "\n",
      "requires(rule(anti_money_laundering_rule), requirement(rule(anti_money_laundering_rule), $10,000)).\n",
      "requires(rule(consumer_protection_law), requirement(rule(consumer_protection_law), 30)).\n",
      "requires(rule(data_privacy_and_security_law), requirement(rule(data_privacy_and_security_law), true)).\n",
      "requires(rule(employment_laws), requirement(rule(employment_laws), false)).\n",
      "requires(rule(credit_reporting_laws), requirement(rule(credit_reporting_laws), 650)).\n",
      "requires(rule(tax_compliance_law), requirement(rule(tax_compliance_law), 20)).\n",
      "\n",
      "implies(rule(anti_money_laundering_rule), implication(rule(anti_money_laundering_rule), rule(consumer_protection_law)).\n",
      "implies(rule(data_privacy_and_security_law), implication(rule(data_privacy_and_security_law), rule(tpcl))).\n",
      "implies(rule(employment_laws), implication(rule(employment_laws), rule(epl))).\n",
      "implies(rule(credit_reporting_laws), implication(rule(credit_reporting_laws), rule(bcl))).\n",
      "implies(rule(tax_compliance_law), implication(rule(tax_compliance_law), rule(tpl))).\n",
      "\n",
      "includes(rule(tpcl), rule(terms_and_conditions_law)).\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a8c760ab9d0fcfb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
