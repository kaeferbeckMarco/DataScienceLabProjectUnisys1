{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T13:01:19.413331Z",
     "start_time": "2024-10-29T13:01:15.444972Z"
    }
   },
   "source": "%pip install llamaapi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llamaapi in c:\\users\\anwender\\anaconda3\\lib\\site-packages (0.1.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.5 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from llamaapi) (3.8.5)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from llamaapi) (1.5.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from llamaapi) (2.31.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.27.1->llamaapi) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:01:24.318408Z",
     "start_time": "2024-10-29T13:01:22.540409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from llamaapi import LlamaAPI\n",
    "\n",
    "# Initialize the SDK\n",
    "llama = LlamaAPI(\"LA-b4008bdd31074aeda467ce7aee0507c8544bc72bd2634ca7a574a668e54e586d\")\n",
    "\n",
    "# Build the API request\n",
    "api_request_json = {\n",
    "    \"model\": \"llama3.1-70b\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in Vienna?\"},\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"days\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"for how many days ahead you wants the forecast\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"days\"],\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"function_call\": \"get_current_weather\",\n",
    "}\n",
    "\n",
    "# Execute the Request\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))\n"
   ],
   "id": "a3a77ea57786ac66",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "POST 401 Insufficient balance.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 39\u001B[0m\n\u001B[0;32m      8\u001B[0m api_request_json \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama3.1-70b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_current_weather\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     36\u001B[0m }\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Execute the Request\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m response \u001B[38;5;241m=\u001B[39m llama\u001B[38;5;241m.\u001B[39mrun(api_request_json)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(json\u001B[38;5;241m.\u001B[39mdumps(response\u001B[38;5;241m.\u001B[39mjson(), indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llamaapi\\llamaapi.py:67\u001B[0m, in \u001B[0;36mLlamaAPI.run\u001B[1;34m(self, api_request_json)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_stream(api_request_json)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_sync(api_request_json)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\llamaapi\\llamaapi.py:53\u001B[0m, in \u001B[0;36mLlamaAPI.run_sync\u001B[1;34m(self, api_request_json)\u001B[0m\n\u001B[0;32m     51\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhostname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdomain_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, headers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders, json\u001B[38;5;241m=\u001B[39mapi_request_json)\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:        \n\u001B[1;32m---> 53\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mjson()[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdetail\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[1;31mException\u001B[0m: POST 401 Insufficient balance."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:51:29.921720Z",
     "start_time": "2024-10-29T13:51:25.879670Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install openai",
   "id": "ebf5d5012c7a40ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\anwender\\anaconda3\\lib\\site-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (1.10.18)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T13:52:03.234597Z",
     "start_time": "2024-10-29T13:52:02.925346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#https://platform.openai.com/docs/quickstart?desktop-os=windows&language-preference=python\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "\n"
   ],
   "id": "94ee56c3b120250c",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model_json_schema' from 'openai._compat' (C:\\Users\\Anwender\\anaconda3\\Lib\\site-packages\\openai\\_compat.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mopenai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAI\n\u001B[0;32m      2\u001B[0m client \u001B[38;5;241m=\u001B[39m OpenAI()\n\u001B[0;32m      4\u001B[0m completion \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m      5\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-4o-mini\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m     messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m     ]\n\u001B[0;32m     13\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\__init__.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m file_from_path\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_client\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Client, OpenAI, Stream, Timeout, Transport, AsyncClient, AsyncOpenAI, AsyncStream, RequestOptions\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __title__, __version__\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_client.py:11\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping_extensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Self, override\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mhttpx\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m resources, _exceptions\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_qs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Querystring\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     14\u001B[0m     NOT_GIVEN,\n\u001B[0;32m     15\u001B[0m     Omit,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     RequestOptions,\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbeta\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Beta,\n\u001B[0;32m      5\u001B[0m     AsyncBeta,\n\u001B[0;32m      6\u001B[0m     BetaWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncBetaWithRawResponse,\n\u001B[0;32m      8\u001B[0m     BetaWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncBetaWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Chat,\n\u001B[0;32m     13\u001B[0m     AsyncChat,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncChatWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     Audio,\n\u001B[0;32m     21\u001B[0m     AsyncAudio,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     AsyncAudioWithStreamingResponse,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbeta\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Beta,\n\u001B[0;32m      5\u001B[0m     AsyncBeta,\n\u001B[0;32m      6\u001B[0m     BetaWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncBetaWithRawResponse,\n\u001B[0;32m      8\u001B[0m     BetaWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncBetaWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Threads,\n\u001B[0;32m     13\u001B[0m     AsyncThreads,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncThreadsWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01massistants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     Assistants,\n\u001B[0;32m     21\u001B[0m     AsyncAssistants,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     AsyncAssistantsWithStreamingResponse,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\beta.py:5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m annotations\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      6\u001B[0m     Threads,\n\u001B[0;32m      7\u001B[0m     AsyncThreads,\n\u001B[0;32m      8\u001B[0m     ThreadsWithRawResponse,\n\u001B[0;32m      9\u001B[0m     AsyncThreadsWithRawResponse,\n\u001B[0;32m     10\u001B[0m     ThreadsWithStreamingResponse,\n\u001B[0;32m     11\u001B[0m     AsyncThreadsWithStreamingResponse,\n\u001B[0;32m     12\u001B[0m )\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cached_property\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01massistants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     15\u001B[0m     Assistants,\n\u001B[0;32m     16\u001B[0m     AsyncAssistants,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     AsyncAssistantsWithStreamingResponse,\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\threads\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Runs,\n\u001B[0;32m      5\u001B[0m     AsyncRuns,\n\u001B[0;32m      6\u001B[0m     RunsWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncRunsWithRawResponse,\n\u001B[0;32m      8\u001B[0m     RunsWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncRunsWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Threads,\n\u001B[0;32m     13\u001B[0m     AsyncThreads,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncThreadsWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     20\u001B[0m     Messages,\n\u001B[0;32m     21\u001B[0m     AsyncMessages,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     AsyncMessagesWithStreamingResponse,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Runs,\n\u001B[0;32m      5\u001B[0m     AsyncRuns,\n\u001B[0;32m      6\u001B[0m     RunsWithRawResponse,\n\u001B[0;32m      7\u001B[0m     AsyncRunsWithRawResponse,\n\u001B[0;32m      8\u001B[0m     RunsWithStreamingResponse,\n\u001B[0;32m      9\u001B[0m     AsyncRunsWithStreamingResponse,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msteps\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     Steps,\n\u001B[0;32m     13\u001B[0m     AsyncSteps,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     AsyncStepsWithStreamingResponse,\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     20\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSteps\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsyncSteps\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsyncRunsWithStreamingResponse\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     33\u001B[0m ]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\runs.py:34\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_streaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Stream, AsyncStream\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpagination\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SyncCursorPage, AsyncCursorPage\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_base_client\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m---> 34\u001B[0m     AsyncPaginator,\n\u001B[0;32m     35\u001B[0m     make_request_options,\n\u001B[0;32m     36\u001B[0m )\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstreaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     38\u001B[0m     AssistantEventHandler,\n\u001B[0;32m     39\u001B[0m     AssistantEventHandlerT,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     43\u001B[0m     AsyncAssistantStreamManager,\n\u001B[0;32m     44\u001B[0m )\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbeta\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthreads\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     46\u001B[0m     run_list_params,\n\u001B[0;32m     47\u001B[0m     run_create_params,\n\u001B[0;32m     48\u001B[0m     run_update_params,\n\u001B[0;32m     49\u001B[0m     run_submit_tool_outputs_params,\n\u001B[0;32m     50\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pydantic_function_tool \u001B[38;5;28;01mas\u001B[39;00m pydantic_function_tool\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_parsing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ResponseFormatT \u001B[38;5;28;01mas\u001B[39;00m ResponseFormatT\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\_tools.py:7\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, cast\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_strict_json_schema\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ChatCompletionToolParam\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mshared_params\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FunctionDefinition\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\_pydantic.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NOT_GIVEN\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_dict \u001B[38;5;28;01mas\u001B[39;00m _is_dict, is_list\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PYDANTIC_V2, model_json_schema\n\u001B[0;32m     13\u001B[0m _T \u001B[38;5;241m=\u001B[39m TypeVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_T\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_strict_json_schema\u001B[39m(model: \u001B[38;5;28mtype\u001B[39m[pydantic\u001B[38;5;241m.\u001B[39mBaseModel] \u001B[38;5;241m|\u001B[39m pydantic\u001B[38;5;241m.\u001B[39mTypeAdapter[Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]:\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'model_json_schema' from 'openai._compat' (C:\\Users\\Anwender\\anaconda3\\Lib\\site-packages\\openai\\_compat.py)"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T14:29:32.581229Z",
     "start_time": "2024-10-29T14:29:27.527829Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install ollama",
   "id": "7ca5a2b8c7301944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Obtaining dependency information for ollama from https://files.pythonhosted.org/packages/6a/ca/d22905ac3f768523f778189d38c9c6cd9edf4fa9dd09cb5a3fc57b184f90/ollama-0.3.3-py3-none-any.whl.metadata\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anwender\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T14:34:38.246238Z",
     "start_time": "2024-10-29T14:34:36.882788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me an interesting fact about elephants\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ],
   "id": "64de44d737780c13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an interesting fact about elephants:\n",
      "\n",
      "Elephants have a highly developed brain and are considered one of the smartest animals on Earth. In fact, they have been shown to possess a level of cognitive ability similar to that of primates and dolphins, which are known for their intelligence.\n",
      "\n",
      "One fascinating example of this is their use of tools. Elephants have been observed using sticks to retrieve food from hard-to-reach places, and even using rocks to open shells and access the tasty treats inside. They've also been known to use branches as trunks to lift and move objects that are too heavy for them to lift with just their trunk alone!\n",
      "\n",
      "This level of intelligence and problem-solving ability is truly remarkable, and highlights just how fascinating and complex these incredible creatures can be!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T14:44:18.942567Z",
     "start_time": "2024-10-29T14:44:15.570215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Function to read the content of a PDF document\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Replace this with the path to your PDF document\n",
    "file_path = \"resources/business_rules_document.pdf\"\n",
    "\n",
    "# Read the content of the PDF document\n",
    "document_content = read_pdf(file_path)\n",
    "\n",
    "# Create the Ollama API request\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"I have the following document: {document_content}\\n\\n extract all the business rules from this document. Present them clearly in a bullet-point format.\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Extract and print the response\n",
    "print(response[\"message\"][\"content\"])\n"
   ],
   "id": "670c08e96921729c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted business rules in a clear, bullet-point format:\n",
      "\n",
      "* **Customer Management**\n",
      " + Rule 1: Customers must provide valid identification before opening an account.\n",
      " + Rule 7: Customers must agree to the terms and conditions before using the service.\n",
      "\n",
      "* **Transaction Management**\n",
      " + Rule 2: All transactions above $10,000 must be reported to the compliance department.\n",
      " \n",
      "* **Credit Application**\n",
      " + Rule 3: Loan applications can only be processed if the applicant has a credit score of 650 or above.\n",
      "\n",
      "* **Employee Management**\n",
      " + Rule 4: Employees are not allowed to approve their own expense reports.\n",
      "\n",
      "* **Refund Policy**\n",
      " + Rule 5: Refunds are only issued if the request is made within 30 days of the purchase date.\n",
      "\n",
      "* **Discount Policy**\n",
      " + Rule 6: A manager must approve any discount greater than 20%.\n",
      "\n",
      "* **Data Security and Privacy**\n",
      " + Rule 8: All customer data must be encrypted when stored or transmitted.\n",
      "\n",
      "* **Procurement Process**\n",
      " + Rule 9: Vendors must be vetted and approved by the procurement team before any contracts are signed.\n",
      "\n",
      "* **Inventory Management**\n",
      " + Rule 10: Inventory checks must be conducted at the end of each month.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3153f6e4491d43fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
